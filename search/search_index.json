{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to project carbonify \u00b6 Project name : carbonify Library name : carbonify Authors : Ekimetrics Description : Open source library for carbon accounting and Lifecycle analysis Project Structure \u00b6 - carbonify/ ----- Your python library (only .py files) - data/ - raw/ - processed/ - docs/ # Documentation folder and website (.md, .ipynb) using Mkdocs - notebooks/ # Jupyter notebooks only (.ipynb) - scripts/ # Every automation script (.bat, .py, .sh) - tests/ # Unitary testing using pytst - .gitignore # Configuration file to ignore files on Bitbucket/Github - bitbucket-pipelines.yml # Automation \"as-code\" in Bitbucket - mkdocs.yml # Documentation configuration - requirements.txt # Dependencies to use the library in a blank environment - setup.py # Configuration file to export and package the library Starter package \u00b6 This project has been created using the Ekimetrics Python Starter Package to enforce best coding practices, reusability and industrialization. If you have any questions please reach out to the inno team and Th\u00e9o Alves Da Costa Important Commands \u00b6 mkdocs serve - to launch the documentation.","title":"Welcome to project carbonify"},{"location":"#welcome-to-project-carbonify","text":"Project name : carbonify Library name : carbonify Authors : Ekimetrics Description : Open source library for carbon accounting and Lifecycle analysis","title":"Welcome to project carbonify"},{"location":"#project-structure","text":"- carbonify/ ----- Your python library (only .py files) - data/ - raw/ - processed/ - docs/ # Documentation folder and website (.md, .ipynb) using Mkdocs - notebooks/ # Jupyter notebooks only (.ipynb) - scripts/ # Every automation script (.bat, .py, .sh) - tests/ # Unitary testing using pytst - .gitignore # Configuration file to ignore files on Bitbucket/Github - bitbucket-pipelines.yml # Automation \"as-code\" in Bitbucket - mkdocs.yml # Documentation configuration - requirements.txt # Dependencies to use the library in a blank environment - setup.py # Configuration file to export and package the library","title":"Project Structure"},{"location":"#starter-package","text":"This project has been created using the Ekimetrics Python Starter Package to enforce best coding practices, reusability and industrialization. If you have any questions please reach out to the inno team and Th\u00e9o Alves Da Costa","title":"Starter package"},{"location":"#important-commands","text":"mkdocs serve - to launch the documentation.","title":"Important Commands"},{"location":"best-practices/about/","text":"Excellence in Data Science programming \u00b6 Why excellence in Data Science programming? \u00b6 Writing perfect code is important. It allows you to collaborate efficiently in technical teams, re-use your code , and create code that is industrialized-by-design . How to reach excellence? What are the best practices? \u00b6 To reach excellence in programming, you need to learn and master many different topics: Adopt programming standards & writing conventions Using the right tools to work Version your code","title":"About"},{"location":"best-practices/about/#excellence-in-data-science-programming","text":"","title":"Excellence in Data Science programming"},{"location":"best-practices/about/#why-excellence-in-data-science-programming","text":"Writing perfect code is important. It allows you to collaborate efficiently in technical teams, re-use your code , and create code that is industrialized-by-design .","title":"Why excellence in Data Science programming?"},{"location":"best-practices/about/#how-to-reach-excellence-what-are-the-best-practices","text":"To reach excellence in programming, you need to learn and master many different topics: Adopt programming standards & writing conventions Using the right tools to work Version your code","title":"How to reach excellence? What are the best practices?"},{"location":"best-practices/conventions/","text":"","title":"Conventions"},{"location":"home/ethics/","text":"Ethics checklist \u00b6 Note This checklist will guide you through the ethical aspects to consider when approaching a problem. You should always read this list, make sure you are at least aware of this point. And ideally respect them. This checklist is inspired from the Deon checklist Tip To update/edit the list and tick what you have verified, update the markdown file ethics.md and tick each point by adding a [ x ] Data Collection \u00b6 Informed consent : If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent? Collection bias : Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those? Limit PII exposure : Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis? Data Storage \u00b6 Data security : Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)? Right to be forgotten : Do we have a mechanism through which an individual can request their personal information be removed? Data retention plan : Is there a schedule or plan to delete the data after it is no longer needed? Analysis \u00b6 Missing perspectives : Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)? Dataset bias : Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)? Honest representation : Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data? Privacy in analysis : Have we ensured that data with PII are not used or displayed unless necessary for the analysis? Auditability : Is the process of generating the analysis well documented and reproducible if we discover issues in the future? Modeling \u00b6 Proxy discrimination : Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory? Fairness across groups : Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)? Metric selection : Have we considered the effects of optimizing for our defined metrics and considered additional metrics? Explainability : Can we explain in understandable terms a decision the model made in cases where a justification is needed? Communicate bias : Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood? Deployment \u00b6 Redress : Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)? Roll back : Is there a way to turn off or roll back the model in production if necessary? Concept drift : Do we test and monitor for concept drift to ensure the model remains fair over time? Unintended use : Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?","title":"Ethics checklist"},{"location":"home/ethics/#ethics-checklist","text":"Note This checklist will guide you through the ethical aspects to consider when approaching a problem. You should always read this list, make sure you are at least aware of this point. And ideally respect them. This checklist is inspired from the Deon checklist Tip To update/edit the list and tick what you have verified, update the markdown file ethics.md and tick each point by adding a [ x ]","title":"Ethics checklist"},{"location":"home/ethics/#data-collection","text":"Informed consent : If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent? Collection bias : Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those? Limit PII exposure : Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?","title":"Data Collection"},{"location":"home/ethics/#data-storage","text":"Data security : Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)? Right to be forgotten : Do we have a mechanism through which an individual can request their personal information be removed? Data retention plan : Is there a schedule or plan to delete the data after it is no longer needed?","title":"Data Storage"},{"location":"home/ethics/#analysis","text":"Missing perspectives : Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)? Dataset bias : Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)? Honest representation : Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data? Privacy in analysis : Have we ensured that data with PII are not used or displayed unless necessary for the analysis? Auditability : Is the process of generating the analysis well documented and reproducible if we discover issues in the future?","title":"Analysis"},{"location":"home/ethics/#modeling","text":"Proxy discrimination : Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory? Fairness across groups : Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)? Metric selection : Have we considered the effects of optimizing for our defined metrics and considered additional metrics? Explainability : Can we explain in understandable terms a decision the model made in cases where a justification is needed? Communicate bias : Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?","title":"Modeling"},{"location":"home/ethics/#deployment","text":"Redress : Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)? Roll back : Is there a way to turn off or roll back the model in production if necessary? Concept drift : Do we test and monitor for concept drift to ensure the model remains fair over time? Unintended use : Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?","title":"Deployment"},{"location":"home/faq/","text":"","title":"FAQ"},{"location":"home/installation/","text":"Installation \u00b6 Use locally \u00b6 You can simply clone the bitbucket/github repository locally on your computer and use it ! Install from wheel ( .whl ) file \u00b6 If you have a file .whl containing the library (e.g. library-name.whl ), you can install it with the following pip install library-name.whl Install from source \u00b6 You can also install the repository by cloning it locally, creating the wheel with the following command python setup.py sdist bdist_wheel It will generate the wheel file to install with the previous command Install from the artifactory \u00b6 TBD","title":"Installation"},{"location":"home/installation/#installation","text":"","title":"Installation"},{"location":"home/installation/#use-locally","text":"You can simply clone the bitbucket/github repository locally on your computer and use it !","title":"Use locally"},{"location":"home/installation/#install-from-wheel-whl-file","text":"If you have a file .whl containing the library (e.g. library-name.whl ), you can install it with the following pip install library-name.whl","title":"Install from wheel (.whl) file"},{"location":"home/installation/#install-from-source","text":"You can also install the repository by cloning it locally, creating the wheel with the following command python setup.py sdist bdist_wheel It will generate the wheel file to install with the previous command","title":"Install from source"},{"location":"home/installation/#install-from-the-artifactory","text":"TBD","title":"Install from the artifactory"},{"location":"home/quickstart/","text":"","title":"Quickstart"},{"location":"home/releases/","text":"","title":"Releases"},{"location":"library/utils/","text":"Utils \u00b6 \u00b6 funcname ( self , parameter_list ) \u00b6 Do whatever Parameters: Name Type Description Default parameter_list int Input parameter required Source code in carbonify/utils.py def funcname ( self , parameter_list : int ): \"\"\"Do whatever Args: parameter_list (int): Input parameter \"\"\" pass","title":"Utils"},{"location":"library/utils/#utils","text":"","title":"Utils"},{"location":"library/utils/#carbonify.utils","text":"","title":"carbonify.utils"},{"location":"library/utils/#carbonify.utils.funcname","text":"Do whatever Parameters: Name Type Description Default parameter_list int Input parameter required Source code in carbonify/utils.py def funcname ( self , parameter_list : int ): \"\"\"Do whatever Args: parameter_list (int): Input parameter \"\"\" pass","title":"funcname()"},{"location":"tutorials/notebook-test/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); # Base Data Science snippet import pandas as pd import numpy as np import matplotlib.pyplot as plt import os import time from tqdm import tqdm_notebook % matplotlib inline % load_ext autoreload % autoreload 2 print ( \"hello\" ) hello plt . plot ([ 1 , 2 , 3 ]) [<matplotlib.lines.Line2D at 0x1a660391c88>]","title":"Notebook test"},{"location":"tutorials/quickstart/","text":"","title":"Quickstart"}]}